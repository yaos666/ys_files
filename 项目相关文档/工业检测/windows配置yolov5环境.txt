windows配置yolov5环境训练数据
一、环境配置：
1、conda activate -n yolov5 python=3.8

2、git clone https://github.com/ultralytics/yolov5.git

3、安装相关包：
pip install -r requirements.txt 

pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118

conda install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118

AttributeError: 'FreeTypeFont' object has no attribute 'getsize'
pip install Pillow==9.5.0 -i https://pypi.tuna.tsinghua.edu.cn/simple




二、模型训练
1、运行 gen_files.py 将所有数据集拆分为训练集和测试集合：
D:\YsWrok\Project\yolov5-6.1\dataset\Animal\Animal
修改参数：
	（1）、classes = ['cat', 'dog']
    	（2）、input_dir = "D:\YsWrok\Project\yolov5-6.1\dataset\Animal\VOC2007"
    	（3）、out_dir = "D:\YsWrok\Project\yolov5-6.1\dataset\Animal\Animal"


2、修改模型配置文件：./models/Animal.yaml 配置文件：

修改的参数：
	（1）、nc: 2  # number of classes


3、修改数据配置文件：./data/Animal.yaml

修改的参数：
	train: D:\YsWrok\Project\yolov5-6.1\dataset\Animal\Animal\train\images
	val: D:\YsWrok\Project\yolov5-6.1\dataset\Animal\Animal\val\images
	# Classes
	nc: 2  # number of classes
	names: ['cat', 'dog']  # class names


模型下载：https://github.com/ultralytics/yolov5/releases/tag/v6.1
4、开始训练 train.py ：
python train.py --img 640 --batch 16 --epochs 120 --data ./data/Animal.yaml --cfg ./models/yolov5s_Animal.yaml --weights ./weights/yolov5s.pt --device 0

python train.py --img 640 --batch 16 --epochs 120 --data ./data/Animal.yaml --cfg ./models/yolov5l_Animal.yaml --weights ./weights/yolov5l.pt --device 0

python train.py --img 640 --batch 16 --epochs 120 --data ./data/Animal.yaml --cfg ./models/yolov5x_Animal.yaml --weights ./weights/yolov5x6.pt --device 0

可能出错：
RuntimeError: result type Float can‘t be cast to the desired output type __int64报错解决方法
解决：
https://blog.csdn.net/weixin_54713879/article/details/125612388



注意：防止服务器断开，训练终止：
	python -u t.py >>t.out 2>&1 & 
	

	（1）、训练命令：
		python -u train.py --img 608 --batch 16 --epochs 100 --data ./data/Road_Damage.yaml --cfg ./models/yolov5s_RoadDamage.yaml --weights ./weights/yolov5s.pt --device 0 >>./train_process/img_896.out 2>&1 &
	（2）、进入显示训练界面：
		tail -f ./train_process/img_896.out
	（3）、查看运行的py文件是否真的在运行ing:
		ps -ef|grep python |grep train.py
	（4）、想要中断训练过程，则需要杀掉相应的进程即可：
		kill -9 36289



**********训练结束后***********：

	(1)、会生成两个预训练的模型：
		/home/lwh/yolov5/runs/train/exp12/weights/best.pt：保存的是中间一共比较好模型
		/home/lwh/yolov5/runs/train/exp12/weights/last.pt：训练结束后保存的最后模型
	（2）、在Tensorbaord上查看数据的训练过程中的一些指标:
		/home/lwh/yolov5/runs/train/exp12
	（3）、tensorboard 查看训练过程：./runs/events.out.tfevents.1648556114.ubuntu.34518.0
		（3-1）、tensorboard --logdir=runs
		（3-2）、出现一个网址地址，将网址复制下来到谷歌浏览器打开就可以看到训练的过程
	（4）、模型转换 .pt----->.onnx
		python  export.py --weights weights/yolov5s.pt --include  onnx

python  export.py --weights weights/yolov5s_ming.pt --img 896 --include  onnx
		
		XXXXXX python ../export.py --weights yolov5s_ming.pt -imgsz 896 896 --rect --batch 1 --include=onnx

	**************************************
	（*4*）将yolov5s.pt模型转换为不依托yolov5对应pytorch环境的yolov5s.onnx模型，并进行相应的win下pycharm推理+.xml自动化标注
	           参考：ttps://blog.csdn.net/weixin_45994963/article/details/128338286
	           1）、将/ys/yolov5/export.py中的内容修改成/ys/yolov5/new_export_onnx/change/export_onnx_detect.py
	           2）、将/ys/yolov5/models/yolo.py中的内容修改成/ys/yolov5/new_export_onnx/change/yolo_onnx_detect.py
	           3）、/ys/yolov5路径下执行：
				python export.py --weights yolov5s.pt --img 640 --batch 1 --include=onnx --simplify 
	           4）、/ys/yolov5路径下会生成：
				class_name.txt、yolov5s.onnx
	           5）、运行文件说明：G:\YS_code\ys_project\ONNXProject\yolov5_onnx 在pycharm中打开
			@1、onnx模型单张图片检测：single_detect_onnx.py
			@2、onnx模型单张图片筛选检测（只是检测出筛选出来的类别）：single_SelDetect_onnx.py
			@3、onnx模型多张图片检测：multiple_detect_onnx.py
			@4、onnx模型多张图片筛选检测（只是检测出筛选出来的类别）：multiple_SelDetect_onnx.py
			@5、onnx模型多张图片筛选自动化标注（只是标注出筛选出来的类别，并生成.xml文件）：multiple_SelLabeling_onnx.py
			（在自动化标注过程中有时会，有时又不会出现警告：libpng warning: iCCP: known incorrect sRGB profile）
				*可以不用管，继续将未标注的图片筛选出来跑就好啦
				*目前切换python版本都不能解决，opencv版本未测试
	**************************************




5、使用训练好的预训练模型进行测试：

5-1、图片推理测试：
	（1）、单张图片测试命令：
	python detect.py --source  ./test/Japan_002409.jpg --weights ./runs/train/exp12/weights/best.pt --project ./out --device 0
	（2）、图片目录测试：
	python detect.py --source ./test --weights ./runs/train/exp12/weights/best.pt --project ./out --device 0

	如果检测中有些图片置信度比较低的可以通过--conf-thres参数过滤掉，例如：（默认--conf-thres的值为0.4）
	python detect.py --source ./test --weights ./runs/train/exp12/weights/best.pt --project ./out --conf-thres 0.8



python detect.py --source  test/1.png --weights runs\train\exp15\weights\best.pt --project ./out --device 0





5-2、视频推理测试：
	（1）、python detect.py --source ./test/test.mp4 --weights ./runs/train/exp12/weights/best.pt --project ./out
	（2）、如果想指定输出视频的fourcc格式，用如下命令：
		python detect.py --source ./test/test.mp4 --weights ./runs/train/exp12/weights/best.pt --project ./out --fourcc H264


python detect.py --source ./test/a.mp4 --weights ./weights/PUBLIC_FRIDGE_DYNAMIC_DET_20220919.pt --project ./out


